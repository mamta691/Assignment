{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8873b76d-531b-4b47-856d-99dfb6d54e62",
   "metadata": {},
   "source": [
    "Assignments Question\n",
    "Q1) What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data?\n",
    "\n",
    "\n",
    "Ans) Web scraping is the process of extracting data from websites by using automated software programs or scripts, usually in a structured format such as CSV, JSON, or XML. It involves programmatically downloading and parsing the HTML or XML code of a webpage and extracting the relevant information for analysis or storage.\n",
    "\n",
    "Web scraping is used for various purposes such as data mining, competitive research, market analysis, lead generation, and content aggregation. Here are three areas where web scraping is commonly used:\n",
    "\n",
    "E-commerce: Web scraping is widely used in the e-commerce industry to monitor competitor prices, track product reviews and ratings, gather product descriptions and specifications, and analyze customer feedback and sentiment.\n",
    "\n",
    "Business Intelligence: Web scraping is used in business intelligence to collect data about customers, competitors, and markets. This data is used to identify trends, monitor changes in the industry, and make informed business decisions.\n",
    "\n",
    "Academic Research: Web scraping is used in academic research to collect data from various sources such as social media, news websites, and academic publications. This data is used to conduct quantitative and qualitative analysis, develop models, and draw insights to advance knowledge in a particular field.\n",
    "\n",
    "\n",
    "Q2) What are the different methods used for Web Scraping ?\n",
    "\n",
    "\n",
    "\n",
    "Ans) There are various methods used for web scraping, some of the most common methods are:\n",
    "\n",
    "Parsing HTML and XML code: This involves using libraries like Beautiful Soup, lxml, or htmlparser to parse and extract relevant data from the HTML or XML code of a website.\n",
    "\n",
    "Using APIs: Some websites offer APIs that allow access to their data. This method involves making HTTP requests to the API endpoints to retrieve the data in a structured format.\n",
    "\n",
    "Automated web browsing: This involves using tools like Selenium or Puppeteer to programmatically control a web browser and simulate human interactions to extract data from websites.\n",
    "\n",
    "Reverse engineering APIs: In cases where a website does not offer an API, developers can reverse engineer the API by analyzing the network requests made by the website to retrieve data.\n",
    "\n",
    "\n",
    "Q3) What is Beautiful Soup? Why is it used ?\n",
    "\n",
    "Ans) Beautiful Soup is a Python library used for web scraping purposes. It's a popular library for parsing HTML and XML documents, and it allows programmers to extract the relevant data from a webpage. Beautiful Soup provides a simple and efficient way to navigate and search the HTML or XML code of a webpage, making it easier to extract specific data from a complex document.\n",
    "\n",
    "Beautiful Soup is used in web scraping because it can handle messy and poorly structured HTML and XML code that is difficult to parse with regular expressions. It provides a variety of methods and functions to locate and extract data, including searching for tags, navigating the parse tree, and filtering data based on various attributes.\n",
    "\n",
    "\n",
    "\n",
    "Q4) What is Beautiful Soup? Why is it used ?\n",
    "\n",
    "Ans) In our project the use of the mobiles_review API system, Flask is likely used to build the backend server that handles the requests and responses of the API.\n",
    "\n",
    "The Flask framework provides a simple and flexible way to handle HTTP requests and responses, making it a popular choice for building web APIs. Flask allows developers to define routes, request handlers, and views for their web applications, and provides a range of tools and extensions to simplify development.\n",
    "\n",
    "\n",
    "Q5)Write the names of AWS services used in this project. Also, explain the use of each service. ?\n",
    "\n",
    "Ans) In our project we use AWS Beam and Codepipline.\n",
    "\n",
    "-------------------------------------------------------------------------------------------- End----------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
